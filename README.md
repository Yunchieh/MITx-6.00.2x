# MITx-6.00.2x
Introduction to Computational Thinking and Data Science

## About this course

6.00.2x will teach you how to use computation to accomplish a variety of goals and provides you with a brief introduction to a variety of topics in computational problem solving . This course is aimed at students with some prior programming experience in Python and a rudimentary knowledge of computational complexity. You will spend a considerable amount of time writing programs to implement the concepts covered in the course. For example, you will write a program that will simulate a robot vacuum cleaning a room or will model the population dynamics of viruses replicating and drug treatments in a patient's body.

## Topics covered include:

*Advanced programming in Python 3

*Knapsack problem, Graphs and graph optimization

*Dynamic programming

*Plotting with the pylab package

*Random walks

*Probability, Distributions

*Monte Carlo simulations

*Curve fitting

*Statistical fallacies


## What you'll learn

*Plotting with the pylab package

*Stochastic programming and statistical thinking

*Monte Carlo simulations

## Course Syllabus

**Lecture 1 – Optimization and Knapsack Problem:**
• Computational models
• Intro to optimization
• 0/1 Knapsack Problem
• Greedy solutions

**Lecture 2 – Decision Trees and Dynamic Programming:**
• Decision tree solution to knapsack
• Dynamic programming and knapsack
• Divide and conquer

**Lecture 3 – Graphs:**
• Graph problems
• Shortest path
• Depth first search
• Breadth first search

**Lecture 4 – Plotting:**
• Visualizing Results
• Overlapping Displays
• Adding More Documentation
• Changing Data Display
• An Example

**Lecture 5 – Stochastic Thinking:**
• Rolling a Die
• Random walks

**Lecture 6 – Random Walks:**
• Drunk walk
• Biased random walks
• Treacherous fields

**Lecture 7 – Inferential Statistics:**
• Probabilities
• Confidence intervals

**Lecture 8 – Monte Carlo Simulations:**

**Lecture 9 – Monte Carlo Simulations:**
• Sampling
• Standard error

**Lecture 10 – Experimental Data:**
• Errors in Experimental Observations
• Curve Fitting

**Lecture 11 – Experimental Data:**
• Goodness of Fit
• Using a Model for Predictions

**Lecture 12 – Machine Learning:**
• Feature Vectors
• Distance Metrics • Clustering

**Lecture 13 – Statistical Fallacies**
• Misusing Statistics
• Garbage In Garbage Out
• Data Enhancement
